nn.Conv2d( 3, 7, 3, padding=1)
nn.Conv2d( 7, 7, 3, padding=1)
nn.Conv2d( 7, 1, 3, padding=1)
******************************
[Model_txt_log_path] = C:\Users\alibh\Desktop\My_Qt\Paper_2_PyQT_Pytorch\designed_module\Module_3L_3ich_7och_3k_1p.txt
******************************
[Model_name] = Module_3L_3ich_7och_3k_1p
[Model_code] = 0002_003L
******************************

Epoch 0/9
----------
LR 0.0001
train: loss: 0.797877, dice: 0.989050, bce: 0.606704
val: loss: 0.796273, dice: 0.987813, bce: 0.604734
0m 1s
Epoch 1/9
----------
LR 0.0001
train: loss: 0.796123, dice: 0.989000, bce: 0.603245
val: loss: 0.794515, dice: 0.987755, bce: 0.601274
0m 0s
Epoch 2/9
----------
LR 0.0001
train: loss: 0.794365, dice: 0.988949, bce: 0.599781
val: loss: 0.792751, dice: 0.987694, bce: 0.597808
0m 0s
Epoch 3/9
----------
LR 0.0001
train: loss: 0.792601, dice: 0.988894, bce: 0.596309
val: loss: 0.790980, dice: 0.987629, bce: 0.594330
0m 0s
Epoch 4/9
----------
LR 0.0001
train: loss: 0.790829, dice: 0.988835, bce: 0.592824
val: loss: 0.789199, dice: 0.987560, bce: 0.590837
0m 0s
Epoch 5/9
----------
LR 0.0001
train: loss: 0.789048, dice: 0.988773, bce: 0.589322
val: loss: 0.787406, dice: 0.987487, bce: 0.587325
0m 0s
Epoch 6/9
----------
LR 0.0001
train: loss: 0.787253, dice: 0.988706, bce: 0.585800
val: loss: 0.785597, dice: 0.987408, bce: 0.583787
0m 0s
Epoch 7/9
----------
LR 0.0001
train: loss: 0.785441, dice: 0.988633, bce: 0.582250
val: loss: 0.783770, dice: 0.987323, bce: 0.580218
0m 0s
Epoch 8/9
----------
LR 0.0001
train: loss: 0.783611, dice: 0.988557, bce: 0.578665
val: loss: 0.781920, dice: 0.987231, bce: 0.576609
0m 0s
Epoch 9/9
----------
LR 0.0001
train: loss: 0.781755, dice: 0.988473, bce: 0.575038
val: loss: 0.780041, dice: 0.987132, bce: 0.572951
0m 0s
******************************
Best val loss: 0.780041 at 9 epoch.
******************************
The loss is in this format [sample number, epoch number , binary_cross_entropy_with_logits , defined_loss , total loss, learning rate]
[loss] ={'loss_bce_train': [(0, 0, 0.6079295873641968, 0.9895162582397461, 0.7987229228019714, 0.0001), (50, 0, 0.6075097620487213, 0.9894231259822845, 0.7984664440155029, 0.0001), (100, 0, 0.6071494817733765, 0.9889655907948812, 0.7980575362841288, 0.0001), (150, 0, 0.6067036986351013, 0.9890498965978622, 0.7978767901659012, 0.0001), (200, 1, 0.6044521927833557, 0.9895933866500854, 0.797022819519043, 0.0001), (250, 1, 0.6040708720684052, 0.9892534017562866, 0.7966621518135071, 0.0001), (300, 1, 0.6036630868911743, 0.9890986084938049, 0.796380857626597, 0.0001), (350, 1, 0.6032451391220093, 0.9890004694461823, 0.7961228042840958, 0.0001), (400, 2, 0.6010710000991821, 0.989040195941925, 0.795055627822876, 0.0001), (450, 2, 0.6007197797298431, 0.9885170161724091, 0.7946184277534485, 0.0001), (500, 2, 0.6002242763837179, 0.9889036019643148, 0.7945639689763387, 0.0001), (550, 2, 0.5997811853885651, 0.9889491200447083, 0.7943651676177979, 0.0001), (600, 3, 0.5976763367652893, 0.9885126948356628, 0.7930945158004761, 0.0001), (650, 3, 0.5972335636615753, 0.988562136888504, 0.7928978502750397, 0.0001), (700, 3, 0.5967229604721069, 0.9890330831209818, 0.7928780118624369, 0.0001), (750, 3, 0.5963088423013687, 0.9888937920331955, 0.7926013022661209, 0.0001), (800, 4, 0.5941822528839111, 0.9885236024856567, 0.7913529276847839, 0.0001), (850, 4, 0.5936456918716431, 0.9891597032546997, 0.7914026975631714, 0.0001), (900, 4, 0.5932605465253195, 0.9888389110565186, 0.7910497188568115, 0.0001), (950, 4, 0.5928239673376083, 0.988834872841835, 0.7908294200897217, 0.0001), (1000, 5, 0.5907297134399414, 0.9882306456565857, 0.7894802093505859, 0.0001), (1050, 5, 0.5902505218982697, 0.9884626269340515, 0.7893565893173218, 0.0001), (1100, 5, 0.5898058414459229, 0.9884925484657288, 0.7891492048899332, 0.0001), (1150, 5, 0.5893224328756332, 0.9887732714414597, 0.7890478670597076, 0.0001), (1200, 6, 0.5871316194534302, 0.9886747002601624, 0.7879031896591187, 0.0001), (1250, 6, 0.5867284536361694, 0.9884366393089294, 0.7875825762748718, 0.0001), (1300, 6, 0.5862492322921753, 0.988662600517273, 0.7874559362729391, 0.0001), (1350, 6, 0.5857999920845032, 0.9887056946754456, 0.7872528582811356, 0.0001), (1400, 7, 0.5834763646125793, 0.9893734455108643, 0.7864248752593994, 0.0001), (1450, 7, 0.5830744504928589, 0.9890750646591187, 0.7860747575759888, 0.0001), (1500, 7, 0.5826797882715861, 0.9887470006942749, 0.7857133944829305, 0.0001), (1550, 7, 0.582250103354454, 0.9886327683925629, 0.7854414284229279, 0.0001), (1600, 8, 0.5801247954368591, 0.9878696799278259, 0.7839972376823425, 0.0001), (1650, 8, 0.5795665979385376, 0.9885757565498352, 0.7840711772441864, 0.0001), (1700, 8, 0.5791484713554382, 0.9883682330449423, 0.7837583422660828, 0.0001), (1750, 8, 0.5786653161048889, 0.9885571300983429, 0.7836112231016159, 0.0001), (1800, 9, 0.5764184594154358, 0.988429069519043, 0.782423734664917, 0.0001), (1850, 9, 0.5759508013725281, 0.9884918928146362, 0.7822213172912598, 0.0001), (1900, 9, 0.5755060116449991, 0.9884158770243326, 0.781960924466451, 0.0001), (1950, 9, 0.5750378519296646, 0.9884731620550156, 0.7817554920911789, 0.0001)], 'loss_bce_Val': [(0, 0, 0.6047337651252747, 0.9878126382827759, 0.7962732315063477, 0.0001), (20, 1, 0.6012743711471558, 0.9877550005912781, 0.7945146560668945, 0.0001), (40, 2, 0.5978078246116638, 0.9876939654350281, 0.792750895023346, 0.0001), (60, 3, 0.594329833984375, 0.9876293540000916, 0.7909796237945557, 0.0001), (80, 4, 0.5908368825912476, 0.9875604510307312, 0.789198637008667, 0.0001), (100, 5, 0.5873246192932129, 0.9874865412712097, 0.7874056100845337, 0.0001), (120, 6, 0.583787202835083, 0.9874075055122375, 0.7855973243713379, 0.0001), (140, 7, 0.5802178382873535, 0.987322986125946, 0.7837704420089722, 0.0001), (160, 8, 0.5766085386276245, 0.9872311949729919, 0.7819198369979858, 0.0001), (180, 9, 0.5729508996009827, 0.9871320724487305, 0.7800414562225342, 0.0001)]}
******************************
